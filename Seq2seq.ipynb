{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 1878727,
          "sourceType": "datasetVersion",
          "datasetId": 1118439
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "Seq2seq",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParijatSutradhar04/ML-learning/blob/main/Seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'bilingual-sentence-pairs:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1118439%2F1878727%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240628%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240628T124106Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0ec9650f8067fda440f9f8199e902018b7441be9baa153546b509ec4f0732d1dd7af68e4d1738d5a4845166ad84a566bfba5dd491ad09b49dbb358a085c4dc2d65255abfba6dc3f63876d06b603d70cd8a1be1734108f1312711abc8b6ce9f47eedf3e14dfe53424cf1c92e3bdba19efbcc364ebda7df80949ae649926a12a4c4966aa31ddc759e20992a8b2f64f9aa1a0e33d1f48f37c6ca524111f57ca6a4f30389ef002339b8c6330d9ef4bba1a026297b7bb1c3d70e50134c1957390b5acabceace26537138c40356d6ba4b2f49c5546c75c2db8333ec5d8a08937735fac039002a419b76a65b539572eac092538b2a6fed494dc212daafa498daf749d31'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "RoIM9IEG3RR9"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-22T11:14:56.011492Z",
          "iopub.execute_input": "2024-06-22T11:14:56.011876Z",
          "iopub.status.idle": "2024-06-22T11:14:57.060599Z",
          "shell.execute_reply.started": "2024-06-22T11:14:56.011845Z",
          "shell.execute_reply": "2024-06-22T11:14:57.059488Z"
        },
        "trusted": true,
        "id": "sqStn-aU3RSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:14:57.062372Z",
          "iopub.execute_input": "2024-06-22T11:14:57.062736Z",
          "iopub.status.idle": "2024-06-22T11:14:57.067042Z",
          "shell.execute_reply.started": "2024-06-22T11:14:57.062713Z",
          "shell.execute_reply": "2024-06-22T11:14:57.06594Z"
        },
        "trusted": true,
        "id": "TfRGbtI23RSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_text(filename):\n",
        "    # open the file\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "\n",
        "def to_lines(text):\n",
        "    sents = text.strip().split('\\n')\n",
        "    sents = [i.split('\\t') for i in sents]\n",
        "    return sents"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:14:57.068368Z",
          "iopub.execute_input": "2024-06-22T11:14:57.068773Z",
          "iopub.status.idle": "2024-06-22T11:14:57.077388Z",
          "shell.execute_reply.started": "2024-06-22T11:14:57.068743Z",
          "shell.execute_reply": "2024-06-22T11:14:57.076371Z"
        },
        "trusted": true,
        "id": "iaOrTkFS3RSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_text(\"../input/bilingual-sentence-pairs/deu.txt\")\n",
        "deu_eng = to_lines(data)\n",
        "deu_eng = np.array(deu_eng)\n",
        "\n",
        "print(deu_eng[:10])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:14:57.07938Z",
          "iopub.execute_input": "2024-06-22T11:14:57.079688Z",
          "iopub.status.idle": "2024-06-22T11:14:59.514119Z",
          "shell.execute_reply.started": "2024-06-22T11:14:57.079664Z",
          "shell.execute_reply": "2024-06-22T11:14:59.513145Z"
        },
        "trusted": true,
        "id": "BPh45yW_3RSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
        "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]\n",
        "\n",
        "for i in range(len(deu_eng)):\n",
        "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
        "    deu_eng[i,1] = deu_eng[i,1].lower()\n",
        "\n",
        "eng_l = []\n",
        "deu_l = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in deu_eng[:,0]:\n",
        "      eng_l.append(len(i.split()))\n",
        "\n",
        "for i in deu_eng[:,1]:\n",
        "      deu_l.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
        "\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:14:59.515305Z",
          "iopub.execute_input": "2024-06-22T11:14:59.515579Z",
          "iopub.status.idle": "2024-06-22T11:15:05.93986Z",
          "shell.execute_reply.started": "2024-06-22T11:14:59.515556Z",
          "shell.execute_reply": "2024-06-22T11:15:05.938935Z"
        },
        "trusted": true,
        "id": "b4EY69Kw3RSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deu_eng[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:15:05.941053Z",
          "iopub.execute_input": "2024-06-22T11:15:05.941328Z",
          "iopub.status.idle": "2024-06-22T11:15:05.94766Z",
          "shell.execute_reply.started": "2024-06-22T11:15:05.941303Z",
          "shell.execute_reply": "2024-06-22T11:15:05.946821Z"
        },
        "trusted": true,
        "id": "i2oa8wpA3RSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download fr_core_news_sm"
      ],
      "metadata": {
        "trusted": true,
        "id": "nlx7Zo7U3RSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.optim as optim\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torch.utils.data import DataLoader, Dataset, random_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:29:55.201483Z",
          "iopub.execute_input": "2024-06-22T11:29:55.201873Z",
          "iopub.status.idle": "2024-06-22T11:29:55.208036Z",
          "shell.execute_reply.started": "2024-06-22T11:29:55.201842Z",
          "shell.execute_reply": "2024-06-22T11:29:55.207042Z"
        },
        "trusted": true,
        "id": "sBd47cJq3RSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_en(sentence):\n",
        "    return sentence.lower().split()\n",
        "\n",
        "def tokenize_fr(sentence):\n",
        "    return sentence.lower().split()\n",
        "\n",
        "def yield_tokens(data, tokenizer):\n",
        "    for sentence in data:\n",
        "        yield tokenizer(sentence)\n",
        "\n",
        "tokenizer_en = get_tokenizer(tokenize_en)\n",
        "tokenizer_fr = get_tokenizer(tokenize_fr)\n",
        "\n",
        "vocab_en = build_vocab_from_iterator(yield_tokens(deu_eng[:, 0], tokenizer_en), specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "vocab_fr = build_vocab_from_iterator(yield_tokens(deu_eng[:, 1], tokenizer_fr), specials=['<unk>', '<pad>', '<sos>', '<eos>'])\n",
        "\n",
        "vocab_en.set_default_index(vocab_en['<unk>'])\n",
        "vocab_fr.set_default_index(vocab_fr['<unk>'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:25:40.213274Z",
          "iopub.execute_input": "2024-06-22T11:25:40.213932Z",
          "iopub.status.idle": "2024-06-22T11:25:42.982573Z",
          "shell.execute_reply.started": "2024-06-22T11:25:40.213899Z",
          "shell.execute_reply": "2024-06-22T11:25:42.981791Z"
        },
        "trusted": true,
        "id": "xYFtWAop3RSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, english_sentences, french_sentences, vocab_en, vocab_fr, tokenizer_en, tokenizer_fr):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.french_sentences = french_sentences\n",
        "        self.vocab_en = vocab_en\n",
        "        self.vocab_fr = vocab_fr\n",
        "        self.tokenizer_en = tokenizer_en\n",
        "        self.tokenizer_fr = tokenizer_fr\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = [self.vocab_en['<sos>']] + [self.vocab_en[token] for token in self.tokenizer_en(self.english_sentences[idx])] + [self.vocab_en['<eos>']]\n",
        "        trg = [self.vocab_fr['<sos>']] + [self.vocab_fr[token] for token in self.tokenizer_fr(self.french_sentences[idx])] + [self.vocab_fr['<eos>']]\n",
        "        return torch.tensor(src), torch.tensor(trg)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:26:20.43288Z",
          "iopub.execute_input": "2024-06-22T11:26:20.433706Z",
          "iopub.status.idle": "2024-06-22T11:26:20.441197Z",
          "shell.execute_reply.started": "2024-06-22T11:26:20.433671Z",
          "shell.execute_reply": "2024-06-22T11:26:20.440249Z"
        },
        "trusted": true,
        "id": "CWnMZ4hu3RSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = zip(*batch)\n",
        "    src_batch = pad_sequence(src_batch, padding_value=vocab_en['<pad>'])\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=vocab_fr['<pad>'])\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "dataset = TranslationDataset(deu_eng[:, 0], deu_eng[:, 1], vocab_en, vocab_fr, tokenizer_en, tokenizer_fr)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, collate_fn=collate_fn, shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:31:31.424755Z",
          "iopub.execute_input": "2024-06-22T11:31:31.425092Z",
          "iopub.status.idle": "2024-06-22T11:31:31.450175Z",
          "shell.execute_reply.started": "2024-06-22T11:31:31.425067Z",
          "shell.execute_reply": "2024-06-22T11:31:31.449479Z"
        },
        "trusted": true,
        "id": "KUnN0qvM3RSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src):\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        outputs, (hidden, cell) = self.rnn(embedded)\n",
        "        return hidden, cell"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:31:33.721414Z",
          "iopub.execute_input": "2024-06-22T11:31:33.722079Z",
          "iopub.status.idle": "2024-06-22T11:31:33.728637Z",
          "shell.execute_reply.started": "2024-06-22T11:31:33.72205Z",
          "shell.execute_reply": "2024-06-22T11:31:33.72772Z"
        },
        "trusted": true,
        "id": "D-YcVYh63RSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input, hidden, cell):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
        "        prediction = self.fc_out(output.squeeze(0))\n",
        "        return prediction, hidden, cell\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:31:35.222465Z",
          "iopub.execute_input": "2024-06-22T11:31:35.223116Z",
          "iopub.status.idle": "2024-06-22T11:31:35.23034Z",
          "shell.execute_reply.started": "2024-06-22T11:31:35.223086Z",
          "shell.execute_reply": "2024-06-22T11:31:35.229392Z"
        },
        "trusted": true,
        "id": "cosj_zx53RSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
        "        trg_len = trg.shape[0]\n",
        "        batch_size = trg.shape[1]\n",
        "        trg_vocab_size = self.decoder.fc_out.out_features\n",
        "\n",
        "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        hidden, cell = self.encoder(src)\n",
        "\n",
        "        input = trg[0,:]\n",
        "\n",
        "        for t in range(1, trg_len):\n",
        "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
        "            outputs[t] = output\n",
        "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
        "            top1 = output.argmax(1)\n",
        "            input = trg[t] if teacher_force else top1\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:31:36.836913Z",
          "iopub.execute_input": "2024-06-22T11:31:36.837614Z",
          "iopub.status.idle": "2024-06-22T11:31:36.8488Z",
          "shell.execute_reply.started": "2024-06-22T11:31:36.837584Z",
          "shell.execute_reply": "2024-06-22T11:31:36.847886Z"
        },
        "trusted": true,
        "id": "ezAeA10P3RSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_DIM = len(vocab_en)\n",
        "OUTPUT_DIM = len(vocab_fr)\n",
        "ENC_EMB_DIM = 256\n",
        "DEC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "N_LAYERS = 2\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "PAD_IDX = vocab_fr['<pad>']\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:31:41.575808Z",
          "iopub.execute_input": "2024-06-22T11:31:41.576646Z",
          "iopub.status.idle": "2024-06-22T11:31:43.061087Z",
          "shell.execute_reply.started": "2024-06-22T11:31:41.576613Z",
          "shell.execute_reply": "2024-06-22T11:31:43.060134Z"
        },
        "trusted": true,
        "id": "TTjdW3nz3RSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T11:31:45.283914Z",
          "iopub.execute_input": "2024-06-22T11:31:45.284834Z",
          "iopub.status.idle": "2024-06-22T11:31:45.293746Z",
          "shell.execute_reply.started": "2024-06-22T11:31:45.284803Z",
          "shell.execute_reply": "2024-06-22T11:31:45.292735Z"
        },
        "trusted": true,
        "id": "aqHr-juZ3RSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for i, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output[1:].view(-1, output_dim)\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "N_EPOCHS = 30\n",
        "train_losses = []\n",
        "CLIP = 1\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
        "    train_losses.append(train_loss)\n",
        "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.3f}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "IO94726j3RSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, N_EPOCHS + 1), train_losses, marker='o', label='Train Loss')\n",
        "plt.title('Train Loss vs. Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hRvWYlLR3RSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'seq2seq.pth')"
      ],
      "metadata": {
        "id": "tOCXfeqb3RSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            output = model(src, trg, 0)  # Turn off teacher forcing\n",
        "            output_dim = output.shape[-1]\n",
        "\n",
        "            output = output[1:].view(-1, output_dim)\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "def calculate_bleu(iterator, model, vocab_fr):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (src, trg) in iterator:\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "            output = model(src, trg, 0)  # Turn off teacher forcing\n",
        "            output = output.argmax(2).cpu().numpy()\n",
        "\n",
        "            for i in range(output.shape[1]):\n",
        "                pred_trg = [vocab_fr.lookup_token(idx) for idx in output[:, i] if idx != vocab_fr['<pad>']]\n",
        "                trg_sentence = [vocab_fr.lookup_token(idx) for idx in trg[:, i].cpu().numpy() if idx != vocab_fr['<pad>']]\n",
        "\n",
        "                pred_trgs.append(pred_trg[1:-1])  # Remove <sos> and <eos>\n",
        "                trgs.append([trg_sentence[1:-1]])  # Remove <sos> and <eos>\n",
        "\n",
        "    return bleu_score(pred_trgs, trgs)\n",
        "\n",
        "def test(model, iterator, criterion, vocab_fr):\n",
        "    test_loss = evaluate(model, iterator, criterion)\n",
        "    bleu = calculate_bleu(iterator, model, vocab_fr)\n",
        "\n",
        "    print(f'Loss: {test_loss:.3f} | BLEU: {bleu:.2f}')\n",
        "\n",
        "\n",
        "print(\"Train Evaluation: \")\n",
        "test(model, train_dataloader, criterion, vocab_fr)\n",
        "print(\"Test Evaluation: \")\n",
        "test(model, test_dataloader, criterion, vocab_fr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-22T12:12:43.17006Z",
          "iopub.execute_input": "2024-06-22T12:12:43.170812Z",
          "iopub.status.idle": "2024-06-22T12:15:43.059679Z",
          "shell.execute_reply.started": "2024-06-22T12:12:43.170781Z",
          "shell.execute_reply": "2024-06-22T12:15:43.058787Z"
        },
        "trusted": true,
        "id": "CNy3_0vq3RSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kUMdyrVA3RSL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}